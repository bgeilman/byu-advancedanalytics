{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (21.0.1)\n",
      "Requirement already satisfied: smart-open in /opt/conda/lib/python3.7/site-packages (5.0.0)\n",
      "Requirement already satisfied: flatten_json in /opt/conda/lib/python3.7/site-packages (0.1.13)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from flatten_json) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "# Install exta packages\n",
    "\n",
    "!pip install --upgrade pip\n",
    "!pip install smart-open\n",
    "!pip install flatten_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and set up variables\n",
    "\n",
    "# import the libraries that we will use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from smart_open import open\n",
    "from flatten_json import flatten\n",
    "from datetime import datetime\n",
    "\n",
    "# s3 locations\n",
    "bucket = \"emba-final-project\"\n",
    "in_folder = \"training-data\"\n",
    "out_folder = \"csv\"\n",
    "\n",
    "# input files\n",
    "in_business_file = \"business_test.json\"\n",
    "in_photos_file = \"photos_test.json\"\n",
    "in_review_file = \"review_test.json\"\n",
    "in_user_file = \"user_test.json\"\n",
    "\n",
    "# output files\n",
    "out_business_file = \"business_test.csv\"\n",
    "out_photos_file = \"photos_test.csv\"\n",
    "out_review_file = \"review_test.csv\"\n",
    "out_user_file = \"user_test.csv\"\n",
    "\n",
    "# Comment out the next two groups to use small test files\n",
    "# Uncomment the next two groups to use large training files\n",
    "\n",
    "# input files\n",
    "in_business_file = \"business_train.json\"\n",
    "in_photos_file = \"photos_train.json\"\n",
    "in_review_file = \"review_train.json\"\n",
    "in_user_file = \"user_train.json\"\n",
    "\n",
    "# output files\n",
    "out_business_file = \"business_test.csv\"\n",
    "out_photos_file = \"photos_test.csv\"\n",
    "out_review_file = \"review_test.csv\"\n",
    "out_user_file = \"user_test.csv\"\n",
    "\n",
    "# input paths\n",
    "in_business_path = f's3://{bucket}/{in_folder}/{in_business_file}'\n",
    "in_photos_path = f's3://{bucket}/{in_folder}/{in_photos_file}'\n",
    "in_review_path = f's3://{bucket}/{in_folder}/{in_review_file}'\n",
    "in_user_path = f's3://{bucket}/{in_folder}/{in_user_file}'\n",
    "\n",
    "# output paths\n",
    "out_business_path = f's3://{bucket}/{out_folder}/{out_business_file}'\n",
    "out_photos_path = f's3://{bucket}/{out_folder}/{out_photos_file}'\n",
    "out_review_path = f's3://{bucket}/{out_folder}/{out_review_file}'\n",
    "out_user_path = f's3://{bucket}/{out_folder}/{out_user_file}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a few functions\n",
    "\n",
    "# Add a comma to the string passed in if the last character is not a '{'\n",
    "# i.e. add a comma if we are not starting a new entry in the dict\n",
    "def add_comma_if_needed(dict_str):\n",
    "    if not dict_str.endswith('{'):\n",
    "        dict_str = dict_str + ','\n",
    "    return dict_str\n",
    "\n",
    "\n",
    "##############################\n",
    "\n",
    "\n",
    "# Define function to flatten yelp academic JSON data set\n",
    "def fix_dict(data, list_of_lists = [], dict_of_operations = {}):\n",
    "    new_dict_str = \"{\"\n",
    "    \n",
    "    # Create list of keys from dict_of_operations\n",
    "    list_of_dos = []\n",
    "    for do_key, do_value in dict_of_operations.items():\n",
    "        list_of_dos.append(do_key)\n",
    "    \n",
    "    # Process and fix the JSON string data\n",
    "    for key, value in data.items():\n",
    "\n",
    "        # Check key. If its in the list to operate on its values then:\n",
    "        # step 1) get the operation from dict_of_operations\n",
    "        # step 2) do the operation on the values and use the result\n",
    "        #         as a new value for the key\n",
    "        if key in list_of_dos:\n",
    "            new_dict_str = add_comma_if_needed(new_dict_str)\n",
    "            # Get the operation from the dictionary\n",
    "            operation = dict_of_operations.get(key)\n",
    "            # Initialize new_value\n",
    "            new_value = \"\"\n",
    "            # Convert value to list or dict for operation\n",
    "            # Check if string is really a quoted dictionary\n",
    "            if value.startswith('{') and value.endswith('}'):\n",
    "                pass\n",
    "            # Else make it into a list\n",
    "            else:\n",
    "                # Create list from comma delimited string and remove\n",
    "                # leading and trailing white space\n",
    "                new_list = [x.strip() for x in value.split(',')]\n",
    "            # Find and do the operation\n",
    "            if operation == \"count\":\n",
    "                # Count the items shown in the key's value\n",
    "                new_value = len(new_list)\n",
    "                # If there is only one item and it is \"None\" change count to zero\n",
    "                if new_value == 1 and (new_list[0] == \"None\" or new_list[0] == \"\"):\n",
    "                    new_value = 0\n",
    "            elif operation == \"sum\":\n",
    "                # Add the items shown in the key's value\n",
    "                new_value = sum(new_list)\n",
    "            else:\n",
    "                pass\n",
    "            new_dict_str = new_dict_str + '\"' + str(key) + '\":' + str(new_value)\n",
    "            # Go to the next key since we just did special processing for this key\n",
    "            continue\n",
    "\n",
    "        # Check key. If its in the list to convert its values to:\n",
    "        # step 1) a list\n",
    "        # step 2) a dict of booleans with value True\n",
    "        if key in list_of_lists:\n",
    "            new_dict_str = add_comma_if_needed(new_dict_str)\n",
    "            # Create list from comma delimited string and remove\n",
    "            # leading and trailing white space\n",
    "            new_list = [x.strip() for x in value.split(',')]\n",
    "            # print(new_list)\n",
    "            # Start a new dictionary with the key that got us here\n",
    "            new_dict_str = new_dict_str + '\"' + str(key) + '\":{'\n",
    "            # Iterate over the list and add each item as a key\n",
    "            # with a value of True\n",
    "            for i in new_list:\n",
    "                new_dict_str = add_comma_if_needed(new_dict_str)\n",
    "                new_dict_str = new_dict_str + '\"' + str(i) + '\":' + str(True)\n",
    "            # end the dictionary\n",
    "            new_dict_str = new_dict_str + '}'\n",
    "            # Go to the next key since we just did special processing for this key\n",
    "            continue\n",
    "\n",
    "        # Add int and float entries as is without qoutes\n",
    "        if isinstance(value, (int, float)):\n",
    "            new_dict_str = add_comma_if_needed(new_dict_str)\n",
    "            new_dict_str = new_dict_str + '\"' + str(key) + '\":' + str(value)\n",
    "\n",
    "        # Fix any nested dictionary entries and add them\n",
    "        if isinstance(value, (dict)):\n",
    "            new_dict_str = add_comma_if_needed(new_dict_str)\n",
    "            new_dict_str = new_dict_str + '\"' + str(key) + '\":' + fix_dict(value)\n",
    "\n",
    "        # Add list entries as is without quotes\n",
    "        # (kept this separate from int and float in case future special processing is needed)\n",
    "        if isinstance(value, (list)):\n",
    "            new_dict_str = add_comma_if_needed(new_dict_str)\n",
    "            new_dict_str = new_dict_str + '\"' + str(key) + '\":' + str(value)\n",
    "\n",
    "        # Some strings may actually be a dictionary in quotes\n",
    "        # If it's a quoted dictionary, remove the quotes, fix, and keep it nested in place\n",
    "        # Otherwise, just add the string as is\n",
    "        if isinstance(value, (str)):\n",
    "            new_dict_str = add_comma_if_needed(new_dict_str)\n",
    "            # Check if string is really a quoted dictionary\n",
    "            if value.startswith('{') and value.endswith('}'):\n",
    "                value = eval(value)\n",
    "                new_dict_str = new_dict_str + '\"' + str(key) + '\":' + fix_dict(value)\n",
    "            # if not, just add it as is\n",
    "            else:\n",
    "                new_dict_str = new_dict_str + '\"' + str(key) + '\":\"' + str(value) + '\"'\n",
    "\n",
    "    # Close the dictionary \n",
    "    new_dict_str = new_dict_str + '}'\n",
    "    # and return fixed dictionary (as a string--it gets converted to a dict object upon return)\n",
    "    return new_dict_str\n",
    "\n",
    "\n",
    "##############################\n",
    "\n",
    "\n",
    "def json_string_to_flat_df(line, special_keys = [], operation_keys = {}):\n",
    "\n",
    "    # Replace \"null\" strings with empty strings\n",
    "    line = line.replace(\"null\", \"\\\"\\\"\") # make null look like \"\"\n",
    "    # Remove backslashes that occur at the end of a quoted string\n",
    "    line = line.replace(\"\\\\\\\\\\\",\\\"\", \"\\\",\\\"\") #  make \\\\\",\" look like \",\"\n",
    "    line = line.replace(\"\\\\\\\",\\\"\", \"\\\",\\\"\") # make \\\",\" look like \",\"\n",
    "    # Replace escaped double quotes with a single quote\n",
    "    line = line.replace(\"\\\\\\\"\", \"'\") # make \\\" look like '\n",
    "    # Escape any backslashes that are left with another backslash\n",
    "    line = line.replace(\"\\\\\", \"\\\\\\\\\") # make \\ look like \\\\\n",
    "    \n",
    "    # print(line)\n",
    "    \n",
    "    # Change string to a dictionary object\n",
    "    ydict = eval(line)\n",
    "    # print(ydict)\n",
    "    \n",
    "    # Fix stingified dictionaries and change big string of values into\n",
    "    # into dictionary of booleans\n",
    "    better_ydict = eval(fix_dict(ydict, special_keys, operation_keys))\n",
    "    \n",
    "    # Flatten the dictionary to be added to a DataFrame \n",
    "    ydict_flattened = pd.json_normalize(better_ydict)\n",
    "    \n",
    "    return ydict_flattened\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>attributes.RestaurantsTableService</th>\n",
       "      <th>attributes.WiFi</th>\n",
       "      <th>attributes.BikeParking</th>\n",
       "      <th>...</th>\n",
       "      <th>categories.Vintage &amp; Consignment</th>\n",
       "      <th>categories.Shopping</th>\n",
       "      <th>categories.Furniture Stores</th>\n",
       "      <th>categories.Home &amp; Garden</th>\n",
       "      <th>categories.Beauty &amp; Spas</th>\n",
       "      <th>categories.Hair Salons</th>\n",
       "      <th>categories.Gyms</th>\n",
       "      <th>categories.Active Life</th>\n",
       "      <th>categories.Interval Training Gyms</th>\n",
       "      <th>categories.Fitness &amp; Instruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6iYb2HFDywm3zjuRg0shjw</td>\n",
       "      <td>Oskar Blues Taproom</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>CO</td>\n",
       "      <td>80302</td>\n",
       "      <td>4.0</td>\n",
       "      <td>86</td>\n",
       "      <td>True</td>\n",
       "      <td>u'free'</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tCbdrRPZA0oiIYSmHG3J0w</td>\n",
       "      <td>Flying Elephants at PDX</td>\n",
       "      <td>Portland</td>\n",
       "      <td>OR</td>\n",
       "      <td>97218</td>\n",
       "      <td>4.0</td>\n",
       "      <td>126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u'free'</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bvN78flM8NLprQ1a1y5dRg</td>\n",
       "      <td>The Reclaimory</td>\n",
       "      <td>Portland</td>\n",
       "      <td>OR</td>\n",
       "      <td>97214</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oaepsyvc0J17qwi8cfrOWg</td>\n",
       "      <td>Great Clips</td>\n",
       "      <td>Orange City</td>\n",
       "      <td>FL</td>\n",
       "      <td>32763</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PE9uqAjdw0E4-8mjGl3wVA</td>\n",
       "      <td>Crossfit Terminus</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30316</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                     name         city state  \\\n",
       "0  6iYb2HFDywm3zjuRg0shjw      Oskar Blues Taproom      Boulder    CO   \n",
       "1  tCbdrRPZA0oiIYSmHG3J0w  Flying Elephants at PDX     Portland    OR   \n",
       "2  bvN78flM8NLprQ1a1y5dRg           The Reclaimory     Portland    OR   \n",
       "3  oaepsyvc0J17qwi8cfrOWg              Great Clips  Orange City    FL   \n",
       "4  PE9uqAjdw0E4-8mjGl3wVA        Crossfit Terminus      Atlanta    GA   \n",
       "\n",
       "  postal_code  stars  review_count attributes.RestaurantsTableService  \\\n",
       "0       80302    4.0            86                               True   \n",
       "1       97218    4.0           126                                NaN   \n",
       "2       97214    4.5            13                                NaN   \n",
       "3       32763    3.0             8                                NaN   \n",
       "4       30316    4.0            14                                NaN   \n",
       "\n",
       "  attributes.WiFi attributes.BikeParking  ...  \\\n",
       "0         u'free'                   True  ...   \n",
       "1         u'free'                  False  ...   \n",
       "2             NaN                  False  ...   \n",
       "3             NaN                    NaN  ...   \n",
       "4             NaN                    NaN  ...   \n",
       "\n",
       "  categories.Vintage & Consignment categories.Shopping  \\\n",
       "0                              NaN                 NaN   \n",
       "1                              NaN                 NaN   \n",
       "2                             True                True   \n",
       "3                              NaN                 NaN   \n",
       "4                              NaN                 NaN   \n",
       "\n",
       "  categories.Furniture Stores categories.Home & Garden  \\\n",
       "0                         NaN                      NaN   \n",
       "1                         NaN                      NaN   \n",
       "2                        True                     True   \n",
       "3                         NaN                      NaN   \n",
       "4                         NaN                      NaN   \n",
       "\n",
       "  categories.Beauty & Spas categories.Hair Salons categories.Gyms  \\\n",
       "0                      NaN                    NaN             NaN   \n",
       "1                      NaN                    NaN             NaN   \n",
       "2                      NaN                    NaN             NaN   \n",
       "3                     True                   True             NaN   \n",
       "4                      NaN                    NaN            True   \n",
       "\n",
       "  categories.Active Life categories.Interval Training Gyms  \\\n",
       "0                    NaN                               NaN   \n",
       "1                    NaN                               NaN   \n",
       "2                    NaN                               NaN   \n",
       "3                    NaN                               NaN   \n",
       "4                   True                              True   \n",
       "\n",
       "  categories.Fitness & Instruction  \n",
       "0                              NaN  \n",
       "1                              NaN  \n",
       "2                              NaN  \n",
       "3                              NaN  \n",
       "4                             True  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process business data\n",
    "\n",
    "# Initialize DataFrame\n",
    "bdf = pd.DataFrame([])\n",
    "\n",
    "# Read in the data a line at a time\n",
    "for line in open(in_business_path, encoding='utf8'):\n",
    "    # print(line)\n",
    "    \n",
    "    # Flatten and fix json string to be added to DataFram\n",
    "    flat_df = json_string_to_flat_df(line, ['categories'])\n",
    "    \n",
    "    # Add the flattened dictionary to a DataFrame\n",
    "    bdf = bdf.append(flat_df, ignore_index=True)\n",
    "\n",
    "    \n",
    "# Eliminate unwanted columns\n",
    "bdf.drop( \\\n",
    "         ['address', \\\n",
    "          'latitude', \\\n",
    "          'longitude', \\\n",
    "          'is_open', \\\n",
    "          'hours', \\\n",
    "          'hours.Monday', \\\n",
    "          'hours.Tuesday', \\\n",
    "          'hours.Wednesday', \\\n",
    "          'hours.Thursday', \\\n",
    "          'hours.Friday', \\\n",
    "          'hours.Saturday', \\\n",
    "          'hours.Sunday'], \\\n",
    "         axis=1, \\\n",
    "         inplace=True \\\n",
    "        )    \n",
    "\n",
    "# Save the DataFrame to CSV files, both locally (for easy inspection)\n",
    "# and to an S3 bucket\n",
    "bdf.to_csv(out_business_file) # local\n",
    "bdf.to_csv(out_business_path) # S3\n",
    "\n",
    "# Review DataFrame\n",
    "bdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photo_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>caption</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V1D1gaJLZfQmbUK47yWucw</td>\n",
       "      <td>6iYb2HFDywm3zjuRg0shjw</td>\n",
       "      <td>The Hotbox Coffee Porter is amazing!</td>\n",
       "      <td>drink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JJcbBzWxk1TTNs5XIUP8Ag</td>\n",
       "      <td>tCbdrRPZA0oiIYSmHG3J0w</td>\n",
       "      <td>Almond croissant\\, made fresh in our bakery ev...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bamuoAQPHguDmFvl_BkoOg</td>\n",
       "      <td>tCbdrRPZA0oiIYSmHG3J0w</td>\n",
       "      <td></td>\n",
       "      <td>interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0Hko_ElNxdGSYyC7S6xB2g</td>\n",
       "      <td>tCbdrRPZA0oiIYSmHG3J0w</td>\n",
       "      <td></td>\n",
       "      <td>interior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HUVBN5pqRE6nPYLadGCNZQ</td>\n",
       "      <td>6iYb2HFDywm3zjuRg0shjw</td>\n",
       "      <td>Beers on tap. Really good selection and great ...</td>\n",
       "      <td>interior</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 photo_id             business_id  \\\n",
       "0  V1D1gaJLZfQmbUK47yWucw  6iYb2HFDywm3zjuRg0shjw   \n",
       "1  JJcbBzWxk1TTNs5XIUP8Ag  tCbdrRPZA0oiIYSmHG3J0w   \n",
       "2  bamuoAQPHguDmFvl_BkoOg  tCbdrRPZA0oiIYSmHG3J0w   \n",
       "3  0Hko_ElNxdGSYyC7S6xB2g  tCbdrRPZA0oiIYSmHG3J0w   \n",
       "4  HUVBN5pqRE6nPYLadGCNZQ  6iYb2HFDywm3zjuRg0shjw   \n",
       "\n",
       "                                             caption     label  \n",
       "0               The Hotbox Coffee Porter is amazing!     drink  \n",
       "1  Almond croissant\\, made fresh in our bakery ev...      food  \n",
       "2                                                     interior  \n",
       "3                                                     interior  \n",
       "4  Beers on tap. Really good selection and great ...  interior  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process photo data\n",
    "\n",
    "# Initialize DataFrame\n",
    "pdf = pd.DataFrame([])\n",
    "\n",
    "# Read in the data a line at a time\n",
    "for line in open(in_photos_path, encoding='utf8'):\n",
    "    # print(line)\n",
    "    \n",
    "    # Flatten and fix json string to be added to DataFram\n",
    "    flat_df = json_string_to_flat_df(line)\n",
    "    \n",
    "    # Add the flattened dictionary to a DataFrame\n",
    "    pdf = pdf.append(flat_df, ignore_index=True)\n",
    "\n",
    "\n",
    "# Save the DataFrame to CSV files, both locally (for easy inspection)\n",
    "# and to an S3 bucket\n",
    "pdf.to_csv(out_photos_file) # local\n",
    "pdf.to_csv(out_photos_path) # S3\n",
    "\n",
    "# Review DataFrame\n",
    "pdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>dt_obj</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>review_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NYyoUk7FL6D4EWYiZfzrMw</td>\n",
       "      <td>qU0BZ7yIl8s9ocBy4enISw</td>\n",
       "      <td>G1KjtSHx7L-a_G-TQWEnoA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Yelp came through again! Was in Orlando for th...</td>\n",
       "      <td>2011-07-04 16:13:22</td>\n",
       "      <td>2011-07-04 16:13:22</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>9.746932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROIVLs-_MjKcir9yL9b3yQ</td>\n",
       "      <td>61DrjFcfN1-bS7MrmNA7Jg</td>\n",
       "      <td>LPa3rpKsApYeiQL_qxZ_jA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Eh . . . we wound up here on a whim a few year...</td>\n",
       "      <td>2011-06-24 03:38:20</td>\n",
       "      <td>2011-06-24 03:38:20</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>9.775747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sPWRG7i-gwJjo0nDPr87Dw</td>\n",
       "      <td>24gb1QBBEl2xHtVeTzDsCQ</td>\n",
       "      <td>tCbdrRPZA0oiIYSmHG3J0w</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Elephant's contacted me the same day I posted ...</td>\n",
       "      <td>2012-07-16 05:04:05</td>\n",
       "      <td>2012-07-16 05:04:05</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>8.713276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>w3ge0N2w88RY41-0r7zmcw</td>\n",
       "      <td>7yjvnYDms_mrmBJ75RZlnw</td>\n",
       "      <td>oaepsyvc0J17qwi8cfrOWg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Worst hair cut ever, not only myself but my hu...</td>\n",
       "      <td>2016-10-26 15:23:19</td>\n",
       "      <td>2016-10-26 15:23:19</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>4.432750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I0q_GX7IkjecNdr4lQDzcQ</td>\n",
       "      <td>AsDPajAdVBsXydg60AIsdw</td>\n",
       "      <td>tCbdrRPZA0oiIYSmHG3J0w</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm not usually a fan of airport food. I usual...</td>\n",
       "      <td>2015-04-28 21:11:10</td>\n",
       "      <td>2015-04-28 21:11:10</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>5.929723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  NYyoUk7FL6D4EWYiZfzrMw  qU0BZ7yIl8s9ocBy4enISw  G1KjtSHx7L-a_G-TQWEnoA   \n",
       "1  ROIVLs-_MjKcir9yL9b3yQ  61DrjFcfN1-bS7MrmNA7Jg  LPa3rpKsApYeiQL_qxZ_jA   \n",
       "2  sPWRG7i-gwJjo0nDPr87Dw  24gb1QBBEl2xHtVeTzDsCQ  tCbdrRPZA0oiIYSmHG3J0w   \n",
       "3  w3ge0N2w88RY41-0r7zmcw  7yjvnYDms_mrmBJ75RZlnw  oaepsyvc0J17qwi8cfrOWg   \n",
       "4  I0q_GX7IkjecNdr4lQDzcQ  AsDPajAdVBsXydg60AIsdw  tCbdrRPZA0oiIYSmHG3J0w   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0    4.0       5      2     0   \n",
       "1    3.0       0      0     0   \n",
       "2    4.0       1      0     1   \n",
       "3    1.0       0      0     0   \n",
       "4    5.0       0      0     0   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  Yelp came through again! Was in Orlando for th...  2011-07-04 16:13:22   \n",
       "1  Eh . . . we wound up here on a whim a few year...  2011-06-24 03:38:20   \n",
       "2  Elephant's contacted me the same day I posted ...  2012-07-16 05:04:05   \n",
       "3  Worst hair cut ever, not only myself but my hu...  2016-10-26 15:23:19   \n",
       "4  I'm not usually a fan of airport food. I usual...  2015-04-28 21:11:10   \n",
       "\n",
       "               dt_obj  year  month  hour  review_age  \n",
       "0 2011-07-04 16:13:22  2011      7    16    9.746932  \n",
       "1 2011-06-24 03:38:20  2011      6     3    9.775747  \n",
       "2 2012-07-16 05:04:05  2012      7     5    8.713276  \n",
       "3 2016-10-26 15:23:19  2016     10    15    4.432750  \n",
       "4 2015-04-28 21:11:10  2015      4    21    5.929723  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process review data\n",
    "\n",
    "# Initialize DataFrame\n",
    "rdf = pd.DataFrame([])\n",
    "\n",
    "# Read in the data a line at a time\n",
    "for line in open(in_review_path, encoding='utf8'):\n",
    "    # print(line)\n",
    "    \n",
    "    # Flatten and fix json string to be added to DataFram\n",
    "    flat_df = json_string_to_flat_df(line)\n",
    "    \n",
    "    # Add the flattened dictionary to a DataFrame\n",
    "    rdf = rdf.append(flat_df, ignore_index=True)\n",
    "\n",
    "\n",
    "# Add individual date and time features from existing datetime feature\n",
    "now = datetime.now()\n",
    "rdf['dt_obj'] = pd.to_datetime(rdf['date'], format='%Y-%m-%d %H:%M:%S')\n",
    "rdf['year'] = rdf['dt_obj'].dt.year\n",
    "rdf['month'] = rdf['dt_obj'].dt.month\n",
    "rdf['hour'] = rdf['dt_obj'].dt.hour\n",
    "rdf['review_age'] = now - rdf.dt_obj\n",
    "rdf['review_age'] = rdf.review_age / np.timedelta64(1, 'Y')\n",
    "\n",
    "\n",
    "# Save the DataFrame to CSV files, both locally (for easy inspection)\n",
    "# and to an S3 bucket\n",
    "rdf.to_csv(out_review_file) # local\n",
    "rdf.to_csv(out_review_path) # S3\n",
    "\n",
    "# Review DataFrame\n",
    "rdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>review_count</th>\n",
       "      <th>yelping_since</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>elite</th>\n",
       "      <th>friends</th>\n",
       "      <th>fans</th>\n",
       "      <th>...</th>\n",
       "      <th>compliment_cute</th>\n",
       "      <th>compliment_list</th>\n",
       "      <th>compliment_note</th>\n",
       "      <th>compliment_plain</th>\n",
       "      <th>compliment_cool</th>\n",
       "      <th>compliment_funny</th>\n",
       "      <th>compliment_writer</th>\n",
       "      <th>compliment_photos</th>\n",
       "      <th>dt_obj</th>\n",
       "      <th>yelp_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24gb1QBBEl2xHtVeTzDsCQ</td>\n",
       "      <td>Lisa</td>\n",
       "      <td>94</td>\n",
       "      <td>2011-01-29 01:48:13</td>\n",
       "      <td>278</td>\n",
       "      <td>58</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>352</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29 01:48:13</td>\n",
       "      <td>10.175690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eypq5gLLjCapBVVnMw_MyA</td>\n",
       "      <td>Misha</td>\n",
       "      <td>4880</td>\n",
       "      <td>2007-10-29 08:53:07</td>\n",
       "      <td>4199</td>\n",
       "      <td>2190</td>\n",
       "      <td>3018</td>\n",
       "      <td>14</td>\n",
       "      <td>807</td>\n",
       "      <td>194</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "      <td>93</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>63</td>\n",
       "      <td>11</td>\n",
       "      <td>2007-10-29 08:53:07</td>\n",
       "      <td>13.427516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zoCmtXdUO8Mk9NAYqJCheg</td>\n",
       "      <td>Brad</td>\n",
       "      <td>27</td>\n",
       "      <td>2009-07-01 19:17:38</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-07-01 19:17:38</td>\n",
       "      <td>11.753467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AsDPajAdVBsXydg60AIsdw</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>26</td>\n",
       "      <td>2012-07-26 17:27:46</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-07-26 17:27:46</td>\n",
       "      <td>8.684483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7yjvnYDms_mrmBJ75RZlnw</td>\n",
       "      <td>Lana</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-02 04:10:12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-02 04:10:12</td>\n",
       "      <td>5.000776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id       name  review_count        yelping_since  \\\n",
       "0  24gb1QBBEl2xHtVeTzDsCQ       Lisa            94  2011-01-29 01:48:13   \n",
       "1  Eypq5gLLjCapBVVnMw_MyA      Misha          4880  2007-10-29 08:53:07   \n",
       "2  zoCmtXdUO8Mk9NAYqJCheg       Brad            27  2009-07-01 19:17:38   \n",
       "3  AsDPajAdVBsXydg60AIsdw  Stephanie            26  2012-07-26 17:27:46   \n",
       "4  7yjvnYDms_mrmBJ75RZlnw       Lana             2  2016-04-02 04:10:12   \n",
       "\n",
       "   useful  funny  cool  elite  friends  fans  ...  compliment_cute  \\\n",
       "0     278     58    83      1      352     6  ...                0   \n",
       "1    4199   2190  3018     14      807   194  ...                9   \n",
       "2      32      7     2      0       99     0  ...                0   \n",
       "3      38      4    35      0        1     0  ...                0   \n",
       "4       1      0     0      0        0     0  ...                0   \n",
       "\n",
       "   compliment_list  compliment_note  compliment_plain  compliment_cool  \\\n",
       "0                1                1                10                5   \n",
       "1                4               54                93              124   \n",
       "2                0                0                 0                3   \n",
       "3                0                0                 0                0   \n",
       "4                0                0                 0                0   \n",
       "\n",
       "   compliment_funny  compliment_writer  compliment_photos              dt_obj  \\\n",
       "0                 5                  4                  0 2011-01-29 01:48:13   \n",
       "1               124                 63                 11 2007-10-29 08:53:07   \n",
       "2                 3                  1                  0 2009-07-01 19:17:38   \n",
       "3                 0                  0                  0 2012-07-26 17:27:46   \n",
       "4                 0                  0                  0 2016-04-02 04:10:12   \n",
       "\n",
       "    yelp_age  \n",
       "0  10.175690  \n",
       "1  13.427516  \n",
       "2  11.753467  \n",
       "3   8.684483  \n",
       "4   5.000776  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process user data\n",
    "\n",
    "# Initialize DataFrame\n",
    "udf = pd.DataFrame([])\n",
    "\n",
    "# Read in the data a line at a time\n",
    "for line in open(in_user_path, encoding='utf8'):\n",
    "    # print(line)\n",
    "    \n",
    "    # Flatten and fix json string to be added to DataFram\n",
    "    flat_df = json_string_to_flat_df(line, [], {\"friends\":\"count\",\"elite\":\"count\"})\n",
    "    \n",
    "    # Add the flattened dictionary to a DataFrame\n",
    "    udf = udf.append(flat_df, ignore_index=True)\n",
    "\n",
    "\n",
    "# Add individual date and time features from existing datetime feature\n",
    "now = datetime.now()\n",
    "udf['dt_obj'] = pd.to_datetime(udf['yelping_since'], format='%Y-%m-%d %H:%M:%S')\n",
    "udf['yelp_age'] = now - udf.dt_obj\n",
    "udf['yelp_age'] = udf.yelp_age / np.timedelta64(1, 'Y')\n",
    "\n",
    "\n",
    "# Save the DataFrame to CSV files, both locally (for easy inspection)\n",
    "# and to an S3 bucket\n",
    "udf.to_csv(out_user_file) # local\n",
    "udf.to_csv(out_user_path) # S3\n",
    "\n",
    "# Review DataFrame\n",
    "udf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
